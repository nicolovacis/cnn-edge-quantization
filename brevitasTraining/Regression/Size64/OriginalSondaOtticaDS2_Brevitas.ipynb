{"cells":[{"cell_type":"markdown","metadata":{"id":"G5v6EEiB8NYe"},"source":["## Initialization of the notebook with installation and import of correct versions of libraries."]},{"cell_type":"code","source":["!pip install torchinfo\n","!pip install brevitas\n","!pip install qonnx\n","!pip install onnxoptimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmcktoKYJZh8","executionInfo":{"status":"ok","timestamp":1747670376933,"user_tz":-120,"elapsed":9653,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"eada7de9-2e3d-42e6-ff26-2fdcd2e44018"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n","Requirement already satisfied: brevitas in /usr/local/lib/python3.11/dist-packages (0.12.0)\n","Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.11/dist-packages (from brevitas) (2.0.1)\n","Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.11/dist-packages (from brevitas) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from brevitas) (24.2)\n","Requirement already satisfied: setuptools<70.0 in /usr/local/lib/python3.11/dist-packages (from brevitas) (69.5.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from brevitas) (1.13.1)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from brevitas) (2.6.0+cu124)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from brevitas) (4.13.2)\n","Requirement already satisfied: unfoldNd in /usr/local/lib/python3.11/dist-packages (from brevitas) (0.2.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->brevitas) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->brevitas) (3.0.2)\n","Requirement already satisfied: qonnx in /usr/local/lib/python3.11/dist-packages (0.4.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from qonnx) (25.3.0)\n","Requirement already satisfied: clize>=5.0.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (5.0.2)\n","Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (from qonnx) (3.20.3)\n","Requirement already satisfied: bitstring>=3.1.7 in /usr/local/lib/python3.11/dist-packages (from qonnx) (4.3.1)\n","Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.26.4)\n","Requirement already satisfied: onnx>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.17.0)\n","Requirement already satisfied: onnxruntime>=1.16.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.22.0)\n","Requirement already satisfied: sigtools>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (4.0.1)\n","Requirement already satisfied: toposort>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.10)\n","Requirement already satisfied: bitarray<4.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bitstring>=3.1.7->qonnx) (3.4.1)\n","Requirement already satisfied: od in /usr/local/lib/python3.11/dist-packages (from clize>=5.0.1->qonnx) (2.0.2)\n","Requirement already satisfied: docutils>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from clize>=5.0.1->qonnx) (0.21.2)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (1.13.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.16.1->qonnx) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.16.1->qonnx) (1.3.0)\n","Requirement already satisfied: onnxoptimizer in /usr/local/lib/python3.11/dist-packages (0.3.13)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxoptimizer) (1.17.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxoptimizer) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxoptimizer) (3.20.3)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FbDasl-B7s7B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747670380386,"user_tz":-120,"elapsed":3447,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"b6f860ef-31ab-4589-c3bb-4a61fe6beb94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBlF0FLvsbRa","outputId":"4d93f1c1-713d-4b29-834d-517b6955e01b","executionInfo":{"status":"ok","timestamp":1747670380549,"user_tz":-120,"elapsed":159,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May 19 15:59:40 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zm9jT4jp7bcA","executionInfo":{"status":"ok","timestamp":1747670383096,"user_tz":-120,"elapsed":2544,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[],"source":["import numpy as np\n","import os\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import random\n","import seaborn as sns\n","import pandas as pd\n","import gc\n","import cv2"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim"],"metadata":{"id":"krS2zLgKGigy","executionInfo":{"status":"ok","timestamp":1747670390243,"user_tz":-120,"elapsed":7143,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import brevitas.nn as qnn\n","from brevitas.quant import Int8ActPerTensorFloat\n"],"metadata":{"id":"JpnrBp3tQiVA","executionInfo":{"status":"ok","timestamp":1747670400398,"user_tz":-120,"elapsed":10147,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["read_small = True"],"metadata":{"id":"3GA-pLeNJYEm","executionInfo":{"status":"ok","timestamp":1747670400405,"user_tz":-120,"elapsed":3,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjoOrQGzHLtu","outputId":"f9a07b0d-15f0-4b75-b6db-4b0b6117bf19","executionInfo":{"status":"ok","timestamp":1747670400575,"user_tz":-120,"elapsed":167,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open drive/MyDrive/TecnosensSondaOttica/DatasetTS_MA_small.zip, drive/MyDrive/TecnosensSondaOttica/DatasetTS_MA_small.zip.zip or drive/MyDrive/TecnosensSondaOttica/DatasetTS_MA_small.zip.ZIP.\n"]}],"source":["if read_small:\n","  !unzip drive/MyDrive/TecnosensSondaOttica/DatasetTS_MA_small.zip -d ./dataset\n","else:\n","  !unzip drive/MyDrive/TecnosensSondaOttica/DatasetTS_MA_FT_medium.zip -d ./dataset"]},{"cell_type":"code","source":["datasetPath = \"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelRegression/Dataset\""],"metadata":{"id":"7lZyvbaS3OAR","executionInfo":{"status":"ok","timestamp":1747670400581,"user_tz":-120,"elapsed":3,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Iu1AxdZwbkI","outputId":"556b5e92-997d-44ef-f4e5-05dcbf66f31b","executionInfo":{"status":"ok","timestamp":1747670400690,"user_tz":-120,"elapsed":105,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"markdown","metadata":{"id":"HLn8E57n83U9"},"source":["## Setting a seed on all frameworks for reproducibility"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ThZ9ShCX8H_D","executionInfo":{"status":"ok","timestamp":1747670400742,"user_tz":-120,"elapsed":50,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[],"source":["# Random seed for reproducibility\n","seed = 1234\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"markdown","metadata":{"id":"Lp6Q8Cx2LhdQ"},"source":["# Load data and preprocessing"]},{"cell_type":"markdown","source":["## Generate dataset"],"metadata":{"id":"_sDvgHvuHRzs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQ3aEYIr-lfq"},"outputs":[],"source":["labels_df = pd.read_csv(datasetPath+\"/labels_df2.csv\")\n","#if not read_small:\n","  #labels_df = pd.read_csv(\"../drive/MyDrive/TecnosensSondaOttica/labels_df_ft.csv\", index_col=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Zw2Jb8KscVI"},"outputs":[],"source":["X_train = []\n","Y_train = []\n","X_val = []\n","Y_val = []\n","X_test = []\n","Y_test = []\n","\n","#dir = \"DatasetTS_MA_FT_medium\"\n","if read_small:\n","  dir = datasetPath+\"/DatasetTS_MA_small\"\n","directories = os.listdir(dir)\n","if \".DS_Store\" in directories:\n","    directories.remove(\".DS_Store\")\n","directories = [int(dir) for dir in directories]\n","directories.sort()\n","directories"]},{"cell_type":"code","source":["np.random.seed(42)\n","print(gc.collect())\n","\n","used_angles = [-5,-4,-3,-2,-1,0,1,2,3,4,5]\n","if not read_small:\n","  used_angles = [-5, 5]\n","\n","for directory in tqdm(directories):\n","  if directory in used_angles:\n","    files = os.listdir(dir + '/' + str(directory))\n","    files.sort()\n","    files = list(reversed(files))[:1100]\n","    for file in tqdm(files):\n","      try:\n","        distance_str = file.split('-')[0]\n","        distance_val = int(distance_str)\n","      except:\n","        print(f\"Impossibile estrarre distanza da {file}\")\n","        continue\n","\n","      match = labels_df[(labels_df['distance'] == distance_val) & (labels_df['angle'] == directory)]\n","      if len(match) == 0:\n","        print(f\"Nessuna label trovata per file {file} con distanza {distance_val} e angolo {directory}\")\n","        continue\n","\n","      train_val_test = np.random.randint(0,100)  # 80-5-15 split\n","\n","      image = cv2.imread(dir + \"/\" + str(directory) + \"/\" + file)\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","      if train_val_test < 80:\n","        image = cv2.resize(image, (300,300))\n","        X_train.append(image.astype('float16')/255)\n","        Y_train.append([match.iloc[0]['distance'], match.iloc[0]['angle']])\n","        if len(X_train) != len(Y_train):\n","          print(\"male\", file)\n","          print(len(X_train))\n","          print(len(Y_train))\n","      elif train_val_test < 85:\n","        image = cv2.resize(image, (300,300))\n","        X_val.append(image.astype('float16')/255)\n","        Y_val.append([match.iloc[0]['distance'], match.iloc[0]['angle']])\n","      else:\n","        image = cv2.resize(image, (300,300))\n","        X_test.append(image.astype('float16')/255)\n","        Y_test.append([match.iloc[0]['distance'], match.iloc[0]['angle']])\n","  else:\n","    print(\"Angle \" + str(directory) + \" skipped\")\n"],"metadata":{"id":"s_VQxtqB-qij"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZAlKOLH-lfr"},"outputs":[],"source":["gc.collect()\n","\n","X_train = np.array(X_train)\n","Y_train = np.array(Y_train, dtype=\"float32\")\n","print(\"Shape of Train set's images: \" + str(X_train.shape))\n","print(\"Shape of Train set's labels: \" + str(Y_train.shape))\n","\n","X_val = np.array(X_val)\n","Y_val = np.array(Y_val, dtype=\"float32\")\n","print(\"Shape of Val set's images: \" + str(X_val.shape))\n","print(\"Shape of Val set's labels: \" + str(Y_val.shape))\n","\n","X_test = np.array(X_test)\n","Y_test = np.array(Y_test, dtype=\"float32\")\n","print(\"Shape of Test set's images: \" + str(X_test.shape))\n","print(\"Shape of Test set's labels: \" + str(Y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"68nU-eIx5E-P"},"source":["## Labels Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPKK30bf5E-Q"},"outputs":[],"source":["mean = np.mean(Y_train[:,0])\n","std = np.std(Y_train[:,0])\n","Y_train[:,0] = (Y_train[:,0] - mean)/std\n","Y_val[:,0] = (Y_val[:,0] - mean)/std\n","Y_test[:,0] = (Y_test[:,0] - mean)/std"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpKHBVWB5E-Q"},"outputs":[],"source":["np.max(Y_train[:,0]), np.min(Y_train[:,0]), np.mean(Y_train[:,0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNodeyRr-T0O"},"outputs":[],"source":["mean, std"]},{"cell_type":"markdown","source":["## Save dataset"],"metadata":{"id":"afNHyeES4SVp"}},{"cell_type":"code","source":["save_path = \"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelRegression/Dataset/TensorflowDataset\"\n","\n","os.makedirs(save_path, exist_ok=True)\n","\n","np.save(os.path.join(save_path, \"X_train.npy\"), X_train)\n","np.save(os.path.join(save_path, \"Y_train.npy\"), Y_train)\n","np.save(os.path.join(save_path, \"X_val.npy\"), X_val)\n","np.save(os.path.join(save_path, \"Y_val.npy\"), Y_val)\n","np.save(os.path.join(save_path, \"X_test.npy\"), X_test)\n","np.save(os.path.join(save_path, \"Y_test.npy\"), Y_test)\n"],"metadata":{"id":"fAPMjWgt5h5r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Open Dataset"],"metadata":{"id":"1I2NKOqc6R_O"}},{"cell_type":"code","source":["load_path = \"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelRegression/Dataset/TensorflowDataset\"\n","InputShape=64\n","\n","X_train = np.load(os.path.join(load_path, \"X_train.npy\"))\n","Y_train = np.load(os.path.join(load_path, \"Y_train.npy\"))\n","X_val = np.load(os.path.join(load_path, \"X_val.npy\"))\n","Y_val = np.load(os.path.join(load_path, \"Y_val.npy\"))\n","X_test = np.load(os.path.join(load_path, \"X_test.npy\"))\n","Y_test = np.load(os.path.join(load_path, \"Y_test.npy\"))\n"],"metadata":{"id":"trAJa00F5xzt","executionInfo":{"status":"ok","timestamp":1747671343901,"user_tz":-120,"elapsed":7889,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def resize_set(X):\n","    X = X.astype(np.float32)\n","    resized = np.zeros((X.shape[0], InputShape, InputShape), dtype=np.float32)\n","    for i in range(X.shape[0]):\n","        resized[i] = cv2.resize(X[i], (InputShape, InputShape), interpolation=cv2.INTER_AREA)\n","    return resized\n","\n","X_train = resize_set(X_train)\n","X_val = resize_set(X_val)\n","X_test = resize_set(X_test)\n","\n","print(\"Resized shapes:\")\n","print(\"X_train:\", X_train.shape)\n","print(\"X_val:\", X_val.shape)\n","print(\"X_test:\", X_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROV1UMgKnI17","executionInfo":{"status":"ok","timestamp":1747671352997,"user_tz":-120,"elapsed":9094,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"3c00b08e-3667-4a18-a5f0-aa28304d8db7"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Resized shapes:\n","X_train: (9673, 64, 64)\n","X_val: (590, 64, 64)\n","X_test: (1837, 64, 64)\n"]}]},{"cell_type":"code","source":["class OpticalDataset(torch.utils.data.Dataset):\n","    def __init__(self, X, Y):\n","        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # aggiunge il canale\n","        self.Y = torch.tensor(Y[:,0], dtype=torch.float32)  # solo la distanza normalizzata\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.Y[idx]\n","\n","train_dataset = OpticalDataset(X_train, Y_train)\n","val_dataset = OpticalDataset(X_val, Y_val)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"],"metadata":{"id":"OODtN1lqHXhx","executionInfo":{"status":"ok","timestamp":1747671353106,"user_tz":-120,"elapsed":101,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["test_dataset = OpticalDataset(X_test, Y_test)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"mvuoIodlOB8Y","executionInfo":{"status":"ok","timestamp":1747671353175,"user_tz":-120,"elapsed":68,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNxBi_CeLpIg"},"source":["## Definition of the models"]},{"cell_type":"markdown","source":["\n","\n","```\n","        self.conv1 = qnn.QuantConv2d(1, 8*x, kernel_size=3, stride=1, padding=1,\n","                                     weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                     input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","        self.conv2 = qnn.QuantConv2d(8*x, 12*x, kernel_size=3, stride=1, padding=1,\n","                                     weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                     input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","        self.conv3 = qnn.QuantConv2d(12*x, 16*x, kernel_size=3, stride=1, padding=1,\n","                                     weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                     input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","        self.conv4 = qnn.QuantConv2d(16*x, 20*x, kernel_size=3, stride=1, padding=1,\n","                                     weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                     input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","        self.conv5 = qnn.QuantConv2d(20*x, 24*x, kernel_size=3, stride=1, padding=1,\n","                                     weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                     input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","```\n","\n"],"metadata":{"id":"dBYrD1Uo6W7q"}},{"cell_type":"code","execution_count":32,"metadata":{"id":"3Jrzn2i9zP-T","executionInfo":{"status":"ok","timestamp":1747671353176,"user_tz":-120,"elapsed":4,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[],"source":["import brevitas.nn as qnn\n","from brevitas.quant import Int8ActPerTensorFloat\n","import torch\n","\n","x = 3\n","weight_bit_width = 4\n","InOutQuant = True\n","\n","class StandardModel(torch.nn.Module):\n","    def __init__(self, input_shape=(1, InputShape, InputShape)):\n","        super(StandardModel, self).__init__()\n","        torch.manual_seed(42)\n","\n","\n","        act_bit_width = weight_bit_width\n","\n","        if InOutQuant==False:\n","            self.conv1 = qnn.QuantConv2d(1, 8*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","            self.conv2 = qnn.QuantConv2d(8*x, 12*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","            self.conv3 = qnn.QuantConv2d(12*x, 16*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","            self.conv4 = qnn.QuantConv2d(16*x, 20*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","            self.conv5 = qnn.QuantConv2d(20*x, 24*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","            print(\"InOutQuant False\")\n","        else:\n","            self.conv1 = qnn.QuantConv2d(1, 8*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                        input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","            self.conv2 = qnn.QuantConv2d(8*x, 12*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                        input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","            self.conv3 = qnn.QuantConv2d(12*x, 16*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                        input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","            self.conv4 = qnn.QuantConv2d(16*x, 20*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                        input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","            self.conv5 = qnn.QuantConv2d(20*x, 24*x, kernel_size=3, stride=1, padding=1,\n","                                        weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width,\n","                                        input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","            print(\"InOutQuant True\")\n","\n","        # Activations\n","        self.relu1 = qnn.QuantReLU(bit_width=weight_bit_width)\n","        self.relu2 = qnn.QuantReLU(bit_width=weight_bit_width)\n","        self.relu3 = qnn.QuantReLU(bit_width=weight_bit_width)\n","        self.relu4 = qnn.QuantReLU(bit_width=weight_bit_width)\n","        self.relu5 = qnn.QuantReLU(bit_width=weight_bit_width)\n","        self.relu_fc1 = qnn.QuantReLU(bit_width=weight_bit_width)\n","\n","        # Pooling\n","        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.global_pool = torch.nn.AdaptiveAvgPool2d(1)\n","\n","        # Fully connected layers\n","        self.fc1 = qnn.QuantLinear(24*x, 16*x, weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.out = qnn.QuantLinear(16*x, 1, weight_bit_width=weight_bit_width, bias_bit_width=weight_bit_width)\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu1(self.conv1(x)))  # 128 → 64\n","        x = self.pool(self.relu2(self.conv2(x)))  # 64 → 32\n","        x = self.pool(self.relu3(self.conv3(x)))  # 32 → 16\n","        x = self.pool(self.relu4(self.conv4(x)))  # 16 → 8\n","        x = self.pool(self.relu5(self.conv5(x)))  # 8 → 4\n","        x = self.global_pool(x)                   # 4x4 → 1x1\n","        x = torch.flatten(x, 1)\n","        x = self.relu_fc1(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.out(x)\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"3SArWHvk07FK"},"source":["# Training"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"d1_JgkY7fo5E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"011dc10f-08ad-42ad-ae88-79bacc63c4aa","executionInfo":{"status":"ok","timestamp":1747671989304,"user_tz":-120,"elapsed":636130,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["InOutQuant True\n","Epoch 001 - Train Loss: 0.113588 - Val Loss: 0.199966  --> New best model saved!\n","Epoch 002 - Train Loss: 0.103190 - Val Loss: 0.166244  --> New best model saved!\n","Epoch 003 - Train Loss: 0.152033 - Val Loss: 0.126629  --> New best model saved!\n","Epoch 004 - Train Loss: 0.086091 - Val Loss: 0.090465  --> New best model saved!\n","Epoch 005 - Train Loss: 0.105293 - Val Loss: 0.092320  --> No improvement (1/10)\n","Epoch 006 - Train Loss: 0.070998 - Val Loss: 0.071422  --> New best model saved!\n","Epoch 007 - Train Loss: 0.128920 - Val Loss: 0.066375  --> New best model saved!\n","Epoch 008 - Train Loss: 0.137563 - Val Loss: 0.075656  --> No improvement (1/10)\n","Epoch 009 - Train Loss: 0.197426 - Val Loss: 0.053794  --> New best model saved!\n","Epoch 010 - Train Loss: 0.147819 - Val Loss: 0.054023  --> No improvement (1/10)\n","Epoch 011 - Train Loss: 0.196216 - Val Loss: 0.083202  --> No improvement (2/10)\n","Epoch 012 - Train Loss: 0.041123 - Val Loss: 0.056475  --> No improvement (3/10)\n","Epoch 013 - Train Loss: 0.181474 - Val Loss: 0.091896  --> No improvement (4/10)\n","Epoch 014 - Train Loss: 0.112428 - Val Loss: 0.062992  --> No improvement (5/10)\n","Epoch 015 - Train Loss: 0.098606 - Val Loss: 0.058096  --> No improvement (6/10)\n","Epoch 016 - Train Loss: 0.135896 - Val Loss: 0.058010  --> No improvement (7/10)\n","Epoch 017 - Train Loss: 0.182012 - Val Loss: 0.050885  --> New best model saved!\n","Epoch 018 - Train Loss: 0.119948 - Val Loss: 0.087944  --> No improvement (1/10)\n","Epoch 019 - Train Loss: 0.112312 - Val Loss: 0.050641  --> New best model saved!\n","Epoch 020 - Train Loss: 0.054635 - Val Loss: 0.055192  --> No improvement (1/10)\n","Epoch 021 - Train Loss: 0.138130 - Val Loss: 0.047071  --> New best model saved!\n","Epoch 022 - Train Loss: 0.071763 - Val Loss: 0.054328  --> No improvement (1/10)\n","Epoch 023 - Train Loss: 0.116958 - Val Loss: 0.074316  --> No improvement (2/10)\n","Epoch 024 - Train Loss: 0.123945 - Val Loss: 0.044209  --> New best model saved!\n","Epoch 025 - Train Loss: 0.153897 - Val Loss: 0.053919  --> No improvement (1/10)\n","Epoch 026 - Train Loss: 0.071269 - Val Loss: 0.048085  --> No improvement (2/10)\n","Epoch 027 - Train Loss: 0.110654 - Val Loss: 0.054218  --> No improvement (3/10)\n","Epoch 028 - Train Loss: 0.122066 - Val Loss: 0.069642  --> No improvement (4/10)\n","Epoch 029 - Train Loss: 0.100831 - Val Loss: 0.043319  --> New best model saved!\n","Epoch 030 - Train Loss: 0.105732 - Val Loss: 0.064361  --> No improvement (1/10)\n","Epoch 031 - Train Loss: 0.217088 - Val Loss: 0.047687  --> No improvement (2/10)\n","Epoch 032 - Train Loss: 0.121915 - Val Loss: 0.042845  --> New best model saved!\n","Epoch 033 - Train Loss: 0.115373 - Val Loss: 0.059167  --> No improvement (1/10)\n","Epoch 034 - Train Loss: 0.143640 - Val Loss: 0.055519  --> No improvement (2/10)\n","Epoch 035 - Train Loss: 0.226962 - Val Loss: 0.047453  --> No improvement (3/10)\n","Epoch 036 - Train Loss: 0.128897 - Val Loss: 0.052919  --> No improvement (4/10)\n","Epoch 037 - Train Loss: 0.058795 - Val Loss: 0.056718  --> No improvement (5/10)\n","Epoch 038 - Train Loss: 0.064485 - Val Loss: 0.051567  --> No improvement (6/10)\n","Epoch 039 - Train Loss: 0.082788 - Val Loss: 0.054632  --> No improvement (7/10)\n","Epoch 040 - Train Loss: 0.166907 - Val Loss: 0.041567  --> New best model saved!\n","Epoch 041 - Train Loss: 0.101034 - Val Loss: 0.058421  --> No improvement (1/10)\n","Epoch 042 - Train Loss: 0.098898 - Val Loss: 0.058098  --> No improvement (2/10)\n","Epoch 043 - Train Loss: 0.190691 - Val Loss: 0.056600  --> No improvement (3/10)\n","Epoch 044 - Train Loss: 0.124987 - Val Loss: 0.056327  --> No improvement (4/10)\n","Epoch 045 - Train Loss: 0.176307 - Val Loss: 0.048605  --> No improvement (5/10)\n","Epoch 046 - Train Loss: 0.197665 - Val Loss: 0.069950  --> No improvement (6/10)\n","Epoch 047 - Train Loss: 0.144664 - Val Loss: 0.043909  --> No improvement (7/10)\n","Epoch 048 - Train Loss: 0.114471 - Val Loss: 0.050580  --> No improvement (8/10)\n","Epoch 049 - Train Loss: 0.139412 - Val Loss: 0.062631  --> No improvement (9/10)\n","Epoch 050 - Train Loss: 0.108940 - Val Loss: 0.066534  --> No improvement (10/10)\n","Early stopping triggered.\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = StandardModel().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","criterion = nn.L1Loss()  # Mean Absolute Error\n","\n","best_val_loss = float('inf')\n","patience, patience_counter = 10, 0\n","\n","for epoch in range(1, 1001):\n","    model.train()\n","    train_loss = 0\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device).unsqueeze(1)\n","        #print(f\"Input shape: {inputs.shape}\")\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss = loss.item()  # puoi anche accumulare per media\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device).unsqueeze(1)\n","            outputs = model(inputs)\n","            val_loss += criterion(outputs, targets).item()\n","    val_loss /= len(val_loader)\n","\n","    print(f\"Epoch {epoch:03d} - Train Loss: {train_loss:.6f} - Val Loss: {val_loss:.6f}\", end='')\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model.pth')\n","        patience_counter = 0\n","        print(\"  --> New best model saved!\")\n","    else:\n","        patience_counter += 1\n","        print(f\"  --> No improvement ({patience_counter}/{patience})\")\n","\n","    if patience_counter >= patience:\n","        print(\"Early stopping triggered.\")\n","        break\n"]},{"cell_type":"markdown","metadata":{"id":"tx48dBxt2ZWN"},"source":["## Save the model and collect garbage for resource issues of Colab's RAM"]},{"cell_type":"code","source":["%ls"],"metadata":{"id":"X-bZFbXCarZn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747671989356,"user_tz":-120,"elapsed":74,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"ca2c8298-5f51-4390-c280-04fa2a87adc6"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["best_model.pth  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["from brevitas.export import export_qonnx\n","\n","class QONNXExporter:\n","    def __init__(self, model, model_name, input_shape, export_path):\n","        self.model = model\n","        self.model_name = model_name\n","        self.input_shape = input_shape\n","        self.export_path = export_path\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def export(self):\n","        self.model.to(self.device)\n","        self.model.eval()\n","        dummy_input = torch.randn(self.input_shape).to(self.device)\n","        export_qonnx(self.model, dummy_input, self.export_path)\n","        print(f\"QONNX model exported to: {self.export_path}\\n\")\n"],"metadata":{"id":"J3M45Pe7TFxF","executionInfo":{"status":"ok","timestamp":1747671989361,"user_tz":-120,"elapsed":4,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","EXPORT_DIR = f\"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelRegression/Weights/Size{InputShape}\"\n","if InOutQuant==True:\n","    MODEL_NAME = f\"standardRegressionModel_Size{InputShape}_brevitas_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth{weight_bit_width}_InOutQuant_X{x}\"\n","else:\n","    MODEL_NAME = f\"standardRegressionModel_Size{InputShape}_brevitas_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth{weight_bit_width}_NOInOutQuant_X{x}\"\n","\n","\n","SAVE_DIR = os.path.join(EXPORT_DIR, MODEL_NAME)\n","os.makedirs(SAVE_DIR, exist_ok=True)"],"metadata":{"id":"g5aJHzl4wv1Q","executionInfo":{"status":"ok","timestamp":1747671989370,"user_tz":-120,"elapsed":6,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","execution_count":37,"metadata":{"id":"5tntCRwq2KOz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747671990243,"user_tz":-120,"elapsed":870,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"69ac1afa-8d67-4810-eb34-e505d17e0513"},"outputs":[{"output_type":"stream","name":"stdout","text":["QONNX model exported to: drive/MyDrive/HPPS_Nico/HPPS/Project/ModelRegression/Weights/Size64/standardRegressionModel_Size64_brevitas_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth4_InOutQuant_X3/standardRegressionModel_Size64_brevitas_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth4_InOutQuant_X3.qonnx\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["56"]},"metadata":{},"execution_count":37}],"source":["\n","\n","#model.save(os.path.join(SAVE_DIR, f\"{MODEL_NAME}.keras\"))\n","torch.save(model.state_dict(), os.path.join(SAVE_DIR, f\"{MODEL_NAME}.pth\"))\n","qonnx_export_path = os.path.join(SAVE_DIR, f\"{MODEL_NAME}.qonnx\")\n","exporter = QONNXExporter(model, MODEL_NAME, input_shape=(1, 1, InputShape, InputShape), export_path=qonnx_export_path)\n","exporter.export()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"69JSvioE-1hJ"},"source":["## Predictions"]},{"cell_type":"code","source":["from torchinfo import summary  # Assicurati che torchinfo sia installato\n","\n","# Riassunto del modello\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = StandardModel().to(device)\n","summary(model, input_size=(1, 1, InputShape, InputShape))\n","\n","# Dettagli layer\n","for name, layer in model.named_modules():\n","    if isinstance(layer, (nn.Conv2d, nn.Linear, nn.MaxPool2d, nn.Dropout)):\n","        print(f\"Layer: {name}\")\n","        if isinstance(layer, nn.Conv2d):\n","            print(f\"  Conv2d -> Filters: {layer.out_channels}, Kernel: {layer.kernel_size}, Stride: {layer.stride}, Padding: {layer.padding}\")\n","        if isinstance(layer, nn.Linear):\n","            print(f\"  Linear -> Units: {layer.out_features}\")\n","        if isinstance(layer, nn.MaxPool2d):\n","            print(f\"  MaxPool2d -> Pool size: {layer.kernel_size}\")\n","        if isinstance(layer, nn.Dropout):\n","            print(f\"  Dropout -> Rate: {layer.p}\")\n","        print()\n","\n","# Predizioni su test set\n","model.load_state_dict(torch.load(os.path.join(SAVE_DIR, f\"{MODEL_NAME}.pth\")))\n","#model.load_state_dict(torch.load('best_model.pth'))\n","model.to(device)\n","model.eval()\n","\n","with torch.no_grad():\n","    preds = []\n","    targets = []\n","    for inputs, target in test_loader:\n","        inputs = inputs.to(device)\n","        output = model(inputs).cpu().numpy()\n","        preds.extend(output)\n","        targets.extend(target.numpy())\n","\n","preds = np.array(preds).squeeze()\n","targets = np.array(targets)\n","\n","# Rescaling\n","mean = np.float32(5901007.5)\n","std = np.float32(633870.7)\n","y_test_pred_rescaled = preds * std + mean\n","Y_test_rescaled = targets * std + mean\n","\n","# Errori\n","errors = np.abs(Y_test_rescaled - y_test_pred_rescaled) / 1000  # micrometri\n","avg_error = np.mean(errors)\n","max_error = np.max(errors)\n","min_error = np.min(errors)\n","\n","# Salvataggio su file\n","output_text = (\n","    f\"Average error: {avg_error} micrometers\\n\"\n","    f\"Maximum error: {max_error} micrometers\\n\"\n","    f\"Minimum error: {min_error} micrometers\\n\"\n",")\n","output_file = os.path.join(SAVE_DIR, \"error_report.txt\")\n","with open(output_file, \"w\") as f:\n","    f.write(output_text)\n","\n","# Stampa\n","print(f\"Average error is {avg_error:.6f} micrometers\")\n","print(f\"Maximum error is {max_error:.3f} micrometers\")\n","print(f\"Minimum error is {min_error:.4f} micrometers\")\n"],"metadata":{"id":"sgViktW_JVgV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747671991742,"user_tz":-120,"elapsed":1490,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"3494d013-93e8-4748-f7bd-b48a8188f908"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["InOutQuant True\n","Layer: conv1\n","  Conv2d -> Filters: 24, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv2\n","  Conv2d -> Filters: 36, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv3\n","  Conv2d -> Filters: 48, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv4\n","  Conv2d -> Filters: 60, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv5\n","  Conv2d -> Filters: 72, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: pool\n","  MaxPool2d -> Pool size: 2\n","\n","Layer: fc1\n","  Linear -> Units: 48\n","\n","Layer: dropout\n","  Dropout -> Rate: 0.3\n","\n","Layer: out\n","  Linear -> Units: 1\n","\n","Average error is 41.526173 micrometers\n","Maximum error is 150.682 micrometers\n","Minimum error is 0.0360 micrometers\n"]}]},{"cell_type":"code","source":["print(\"\\nFirst 200 predictions vs ground truth:\\n\")\n","print(\"Idx\\tPredicted [µm]\\tGT [µm]\\t\\tAbsError [µm]\")\n","for i in range(min(200, len(y_test_pred_rescaled))):\n","    pred = y_test_pred_rescaled[i]\n","    gt = Y_test_rescaled[i]\n","    err = abs(pred - gt)\n","    print(f\"{i:03d}\\t{pred:.2f}\\t\\t{gt:.2f}\\t\\t{err:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKWhZYV1YFtB","executionInfo":{"status":"ok","timestamp":1747671991752,"user_tz":-120,"elapsed":8,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"8b163452-ea94-4fca-c7a2-dc70ee79e7b3"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","First 200 predictions vs ground truth:\n","\n","Idx\tPredicted [µm]\tGT [µm]\t\tAbsError [µm]\n","000\t6924098.00\t\t6998000.00\t\t73902.00\n","001\t6926401.50\t\t6986000.00\t\t59598.50\n","002\t6906820.00\t\t6980000.00\t\t73180.00\n","003\t6899908.50\t\t6978000.00\t\t78091.50\n","004\t6901060.50\t\t6966000.00\t\t64939.50\n","005\t6901060.50\t\t6944000.00\t\t42939.50\n","006\t6881479.00\t\t6940000.00\t\t58521.00\n","007\t6881479.00\t\t6934000.00\t\t52521.00\n","008\t6872264.00\t\t6896000.00\t\t23736.00\n","009\t6842315.50\t\t6888000.00\t\t45684.50\n","010\t6842315.50\t\t6880000.00\t\t37684.50\n","011\t6842315.50\t\t6846000.00\t\t3684.50\n","012\t6808912.00\t\t6840000.00\t\t31088.00\n","013\t6812367.50\t\t6830000.00\t\t17632.50\n","014\t6812367.50\t\t6826000.00\t\t13632.50\n","015\t6784723.00\t\t6816000.00\t\t31277.00\n","016\t6804304.50\t\t6798000.00\t\t6304.50\n","017\t6790482.00\t\t6784000.00\t\t6482.00\n","018\t6808912.00\t\t6778000.00\t\t30912.00\n","019\t6797393.00\t\t6772000.00\t\t25393.00\n","020\t6758230.00\t\t6732000.00\t\t26230.00\n","021\t6767445.00\t\t6728000.00\t\t39445.00\n","022\t6772052.50\t\t6724000.00\t\t48052.50\n","023\t6751319.00\t\t6722000.00\t\t29319.00\n","024\t6746711.50\t\t6716000.00\t\t30711.50\n","025\t6739800.00\t\t6704000.00\t\t35800.00\n","026\t6736344.50\t\t6692000.00\t\t44344.50\n","027\t6746711.50\t\t6682000.00\t\t64711.50\n","028\t6723674.00\t\t6678000.00\t\t45674.00\n","029\t6716763.00\t\t6674000.00\t\t42763.00\n","030\t6676448.00\t\t6654000.00\t\t22448.00\n","031\t6672992.50\t\t6624000.00\t\t48992.50\n","032\t6672992.50\t\t6622000.00\t\t50992.50\n","033\t6669536.50\t\t6618000.00\t\t51536.50\n","034\t6660322.00\t\t6594000.00\t\t66322.00\n","035\t6660322.00\t\t6580000.00\t\t80322.00\n","036\t6617703.00\t\t6578000.00\t\t39703.00\n","037\t6560110.00\t\t6550000.00\t\t10110.00\n","038\t6573932.50\t\t6546000.00\t\t27932.50\n","039\t6577388.00\t\t6544000.00\t\t33388.00\n","040\t6563565.50\t\t6542000.00\t\t21565.50\n","041\t6569325.00\t\t6530000.00\t\t39325.00\n","042\t6534769.00\t\t6506000.00\t\t28769.00\n","043\t6534769.00\t\t6502000.00\t\t32769.00\n","044\t6538225.00\t\t6496000.00\t\t42225.00\n","045\t6516339.50\t\t6486000.00\t\t30339.50\n","046\t6530162.00\t\t6474000.00\t\t56162.00\n","047\t6534769.00\t\t6466000.00\t\t68769.00\n","048\t6487543.00\t\t6448000.00\t\t39543.00\n","049\t6459898.50\t\t6444000.00\t\t15898.50\n","050\t6464506.00\t\t6436000.00\t\t28506.00\n","051\t6503669.00\t\t6432000.00\t\t71669.00\n","052\t6455291.00\t\t6426000.00\t\t29291.00\n","053\t6455291.00\t\t6406000.00\t\t49291.00\n","054\t6411520.50\t\t6376000.00\t\t35520.50\n","055\t6389635.00\t\t6374000.00\t\t15635.00\n","056\t6417279.50\t\t6372000.00\t\t45279.50\n","057\t6427646.50\t\t6368000.00\t\t59646.50\n","058\t6423039.00\t\t6350000.00\t\t73039.00\n","059\t6374661.00\t\t6318000.00\t\t56661.00\n","060\t6340105.00\t\t6300000.00\t\t40105.00\n","061\t6365446.00\t\t6294000.00\t\t71446.00\n","062\t6368901.50\t\t6288000.00\t\t80901.50\n","063\t6323979.00\t\t6266000.00\t\t57979.00\n","064\t6306701.00\t\t6262000.00\t\t44701.00\n","065\t6291727.00\t\t6256000.00\t\t35727.00\n","066\t6311308.50\t\t6250000.00\t\t61308.50\n","067\t6287119.50\t\t6244000.00\t\t43119.50\n","068\t6287119.50\t\t6242000.00\t\t45119.50\n","069\t6279056.50\t\t6238000.00\t\t41056.50\n","070\t6282512.00\t\t6230000.00\t\t52512.00\n","071\t6247956.50\t\t6220000.00\t\t27956.50\n","072\t6249108.00\t\t6204000.00\t\t45108.00\n","073\t6243349.00\t\t6194000.00\t\t49349.00\n","074\t6238741.50\t\t6180000.00\t\t58741.50\n","075\t6218008.00\t\t6174000.00\t\t44008.00\n","076\t6179996.50\t\t6142000.00\t\t37996.50\n","077\t6204185.50\t\t6138000.00\t\t66185.50\n","078\t6176541.00\t\t6136000.00\t\t40541.00\n","079\t6168478.00\t\t6130000.00\t\t38478.00\n","080\t6170781.50\t\t6126000.00\t\t44781.50\n","081\t6150048.00\t\t6108000.00\t\t42048.00\n","082\t6123555.50\t\t6092000.00\t\t31555.50\n","083\t6123555.50\t\t6078000.00\t\t45555.50\n","084\t6123555.50\t\t6076000.00\t\t47555.50\n","085\t6124707.50\t\t6072000.00\t\t52707.50\n","086\t6098214.50\t\t6050000.00\t\t48214.50\n","087\t6077481.00\t\t6044000.00\t\t33481.00\n","088\t6061355.00\t\t6042000.00\t\t19355.00\n","089\t6037166.00\t\t6024000.00\t\t13166.00\n","090\t6053292.00\t\t6020000.00\t\t33292.00\n","091\t6032558.50\t\t6004000.00\t\t28558.50\n","092\t6048684.50\t\t5992000.00\t\t56684.50\n","093\t6032558.50\t\t5984000.00\t\t48558.50\n","094\t6026799.00\t\t5978000.00\t\t48799.00\n","095\t6016432.50\t\t5968000.00\t\t48432.50\n","096\t5999154.50\t\t5966000.00\t\t33154.50\n","097\t6012977.00\t\t5958000.00\t\t54977.00\n","098\t6014129.00\t\t5954000.00\t\t60129.00\n","099\t5981877.00\t\t5946000.00\t\t35877.00\n","100\t5994547.00\t\t5940000.00\t\t54547.00\n","101\t5962295.00\t\t5932000.00\t\t30295.00\n","102\t5964599.00\t\t5916000.00\t\t48599.00\n","103\t5949624.50\t\t5912000.00\t\t37624.50\n","104\t5912765.00\t\t5868000.00\t\t44765.00\n","105\t5907006.00\t\t5860000.00\t\t47006.00\n","106\t5892031.50\t\t5856000.00\t\t36031.50\n","107\t5888576.00\t\t5852000.00\t\t36576.00\n","108\t5901246.50\t\t5846000.00\t\t55246.50\n","109\t5874754.00\t\t5830000.00\t\t44754.00\n","110\t5872450.00\t\t5816000.00\t\t56450.00\n","111\t5882817.00\t\t5812000.00\t\t70817.00\n","112\t5878209.50\t\t5806000.00\t\t72209.50\n","113\t5863235.00\t\t5798000.00\t\t65235.00\n","114\t5839046.00\t\t5786000.00\t\t53046.00\n","115\t5868994.50\t\t5784000.00\t\t84994.50\n","116\t5847109.00\t\t5774000.00\t\t73109.00\n","117\t5859779.50\t\t5772000.00\t\t87779.50\n","118\t5822920.00\t\t5762000.00\t\t60920.00\n","119\t5812553.50\t\t5744000.00\t\t68553.50\n","120\t5782605.00\t\t5734000.00\t\t48605.00\n","121\t5728467.50\t\t5724000.00\t\t4467.50\n","122\t5722708.50\t\t5702000.00\t\t20708.50\n","123\t5734227.00\t\t5696000.00\t\t38227.00\n","124\t5714645.50\t\t5694000.00\t\t20645.50\n","125\t5680089.50\t\t5646000.00\t\t34089.50\n","126\t5680089.50\t\t5640000.00\t\t40089.50\n","127\t5663963.50\t\t5620000.00\t\t43963.50\n","128\t5663963.50\t\t5616000.00\t\t47963.50\n","129\t5617889.00\t\t5604000.00\t\t13889.00\n","130\t5610978.00\t\t5598000.00\t\t12978.00\n","131\t5610978.00\t\t5584000.00\t\t26978.00\n","132\t5537259.00\t\t5544000.00\t\t6741.00\n","133\t5539563.00\t\t5516000.00\t\t23563.00\n","134\t5532651.50\t\t5506000.00\t\t26651.50\n","135\t5511918.00\t\t5492000.00\t\t19918.00\n","136\t5516525.50\t\t5488000.00\t\t28525.50\n","137\t5524588.50\t\t5476000.00\t\t48588.50\n","138\t5490033.00\t\t5472000.00\t\t18033.00\n","139\t5532651.50\t\t5454000.00\t\t78651.50\n","140\t5484273.50\t\t5418000.00\t\t66273.50\n","141\t5468147.50\t\t5406000.00\t\t62147.50\n","142\t5468147.50\t\t5404000.00\t\t64147.50\n","143\t5456629.00\t\t5392000.00\t\t64629.00\n","144\t5475058.50\t\t5390000.00\t\t85058.50\n","145\t5475058.50\t\t5380000.00\t\t95058.50\n","146\t5430136.00\t\t5374000.00\t\t56136.00\n","147\t5396732.00\t\t5328000.00\t\t68732.00\n","148\t5374847.00\t\t5326000.00\t\t48847.00\n","149\t5371391.50\t\t5302000.00\t\t69391.50\n","150\t5371391.50\t\t5300000.00\t\t71391.50\n","151\t5367936.00\t\t5274000.00\t\t93936.00\n","152\t5363328.00\t\t5268000.00\t\t95328.00\n","153\t5326469.00\t\t5260000.00\t\t66469.00\n","154\t5333380.00\t\t5254000.00\t\t79380.00\n","155\t5290761.00\t\t5248000.00\t\t42761.00\n","156\t5346050.50\t\t5246000.00\t\t100050.50\n","157\t5309191.00\t\t5218000.00\t\t91191.00\n","158\t5325317.00\t\t5194000.00\t\t131317.00\n","159\t5275787.00\t\t5176000.00\t\t99787.00\n","160\t5295368.50\t\t5170000.00\t\t125368.50\n","161\t5263116.50\t\t5152000.00\t\t111116.50\n","162\t5258509.00\t\t5134000.00\t\t124509.00\n","163\t5234320.00\t\t5124000.00\t\t110320.00\n","164\t5181334.50\t\t5112000.00\t\t69334.50\n","165\t5198612.50\t\t5108000.00\t\t90612.50\n","166\t5136412.00\t\t5090000.00\t\t46412.00\n","167\t5147930.50\t\t5080000.00\t\t67930.50\n","168\t5136412.00\t\t5076000.00\t\t60412.00\n","169\t5141019.50\t\t5072000.00\t\t69019.50\n","170\t5136412.00\t\t5068000.00\t\t68412.00\n","171\t5131804.50\t\t5046000.00\t\t85804.50\n","172\t5129501.00\t\t5040000.00\t\t89501.00\n","173\t5124893.50\t\t5028000.00\t\t96893.50\n","174\t5120286.00\t\t5026000.00\t\t94286.00\n","175\t5096097.00\t\t5004000.00\t\t92097.00\n","176\t5096097.00\t\t5002000.00\t\t94097.00\n","177\t5039656.00\t\t4980000.00\t\t59656.00\n","178\t5046567.00\t\t4956000.00\t\t90567.00\n","179\t5039656.00\t\t4948000.00\t\t91656.00\n","180\t5035048.50\t\t4946000.00\t\t89048.50\n","181\t5010859.50\t\t4928000.00\t\t82859.50\n","182\t5018922.50\t\t4920000.00\t\t98922.50\n","183\t4972848.00\t\t4910000.00\t\t62848.00\n","184\t5024681.50\t\t4874000.00\t\t150681.50\n","185\t4956722.00\t\t4864000.00\t\t92722.00\n","186\t4961329.50\t\t4852000.00\t\t109329.50\n","187\t6941375.50\t\t7000000.00\t\t58624.50\n","188\t6941375.50\t\t6998000.00\t\t56624.50\n","189\t6941375.50\t\t6976000.00\t\t34624.50\n","190\t6931009.00\t\t6960000.00\t\t28991.00\n","191\t6932160.50\t\t6930000.00\t\t2160.50\n","192\t6936768.00\t\t6926000.00\t\t10768.00\n","193\t6909123.50\t\t6908000.00\t\t1123.50\n","194\t6901060.50\t\t6900000.00\t\t1060.50\n","195\t6901060.50\t\t6894000.00\t\t7060.50\n","196\t6875719.50\t\t6858000.00\t\t17719.50\n","197\t6901060.50\t\t6846000.00\t\t55060.50\n","198\t6880327.00\t\t6836000.00\t\t44327.00\n","199\t6889542.00\t\t6826000.00\t\t63542.00\n"]}]},{"cell_type":"markdown","source":["## Add Double Neurons"],"metadata":{"id":"Ny0AMO2zu6xQ"}},{"cell_type":"code","source":["# Aggiunta secondo neurone mantenendo il primo invariato\n","import copy\n","import torch.nn as nn\n","import brevitas.nn as qnn\n","from brevitas.quant import Int8ActPerTensorFloat\n","\n","# Salva stato del vecchio modello\n","model_old = model  # il modello già caricato con output = 1\n","\n","# Crea nuovo modello con stesso backbone ma output a 2 neuroni\n","model_new = copy.deepcopy(model_old)\n","model_new.out = qnn.QuantLinear(16*x, 2, weight_bit_width=8, bias_bit_width=8)\n","\n","# Copia i pesi del primo neurone\n","with torch.no_grad():\n","    model_new.out.weight[0] = model_old.out.weight[0]\n","    model_new.out.bias[0] = model_old.out.bias[0]\n","    model_new.out.weight[1].zero_()\n","    model_new.out.bias[1].zero_()\n","\n","# Invia su device\n","model = model_new.to(device)\n","model.eval()\n","\n","# Riassunto\n","from torchinfo import summary\n","summary(model, input_size=(1, 1, InputShape, InputShape))\n","\n","for name, layer in model.named_modules():\n","    if isinstance(layer, (nn.Conv2d, nn.Linear, nn.MaxPool2d, nn.Dropout)):\n","        print(f\"Layer: {name}\")\n","        if isinstance(layer, nn.Conv2d):\n","            print(f\"  Conv2d -> Filters: {layer.out_channels}, Kernel: {layer.kernel_size}, Stride: {layer.stride}, Padding: {layer.padding}\")\n","        if isinstance(layer, nn.Linear):\n","            print(f\"  Linear -> Units: {layer.out_features}\")\n","        if isinstance(layer, nn.MaxPool2d):\n","            print(f\"  MaxPool2d -> Pool size: {layer.kernel_size}\")\n","        if isinstance(layer, nn.Dropout):\n","            print(f\"  Dropout -> Rate: {layer.p}\")\n","        print()\n","\n","# Predizioni su test set usando solo il primo neurone\n","with torch.no_grad():\n","    preds = []\n","    targets = []\n","    for inputs, target in test_loader:\n","        inputs = inputs.to(device)\n","        output = model(inputs).cpu().numpy()\n","        preds.extend(output[:, 0])  # usa solo il primo neurone\n","        targets.extend(target.numpy())\n","\n","preds = np.array(preds).squeeze()\n","targets = np.array(targets)\n","\n","# Rescaling\n","mean = np.float32(5901007.5)\n","std = np.float32(633870.7)\n","y_test_pred_rescaled = preds * std + mean\n","Y_test_rescaled = targets * std + mean\n","\n","# Errori\n","errors = np.abs(Y_test_rescaled - y_test_pred_rescaled) / 1000  # micrometri\n","avg_error = np.mean(errors)\n","max_error = np.max(errors)\n","min_error = np.min(errors)\n","\n","# Salvataggio su file\n","output_text = (\n","    f\"Average error: {avg_error} micrometers\\n\"\n","    f\"Maximum error: {max_error} micrometers\\n\"\n","    f\"Minimum error: {min_error} micrometers\\n\"\n",")\n","\n","# Percorsi di salvataggio\n","if InOutQuant==True:\n","    MODEL_NAME = f\"standardRegressionModel_Size{InputShape}_brevitas_doubleNeuronsAddedPostTrain_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth{weight_bit_width}_InOutQuant_X{x}\"\n","else:\n","    MODEL_NAME = f\"standardRegressionModel_Size{InputShape}_brevitas_doubleNeuronsAddedPostTrain_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth{weight_bit_width}_NOInOutQuant_X{x}\"\n","\n","\n","SAVE_DIR = os.path.join(EXPORT_DIR, MODEL_NAME)\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","output_file = os.path.join(SAVE_DIR, \"error_report.txt\")\n","with open(output_file, \"w\") as f:\n","    f.write(output_text)\n","\n","print(f\"Average error is {avg_error:.6f} micrometers\")\n","print(f\"Maximum error is {max_error:.3f} micrometers\")\n","print(f\"Minimum error is {min_error:.4f} micrometers\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn3iGr-suMIe","executionInfo":{"status":"ok","timestamp":1747671993225,"user_tz":-120,"elapsed":1471,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"c2db680e-0318-4b4a-cd5d-3d843539d847"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer: conv1\n","  Conv2d -> Filters: 24, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv2\n","  Conv2d -> Filters: 36, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv3\n","  Conv2d -> Filters: 48, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv4\n","  Conv2d -> Filters: 60, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: conv5\n","  Conv2d -> Filters: 72, Kernel: (3, 3), Stride: (1, 1), Padding: (1, 1)\n","\n","Layer: pool\n","  MaxPool2d -> Pool size: 2\n","\n","Layer: fc1\n","  Linear -> Units: 48\n","\n","Layer: dropout\n","  Dropout -> Rate: 0.3\n","\n","Layer: out\n","  Linear -> Units: 2\n","\n","Average error is 48.335304 micrometers\n","Maximum error is 185.764 micrometers\n","Minimum error is 0.0015 micrometers\n"]}]},{"cell_type":"code","source":["from brevitas.export import export_qonnx\n","import os\n","import gc\n","\n","class QONNXExporter:\n","    def __init__(self, model, model_name, input_shape, export_path):\n","        self.model = model\n","        self.model_name = model_name\n","        self.input_shape = input_shape\n","        self.export_path = export_path\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def export(self):\n","        self.model.to(self.device)\n","        self.model.eval()\n","        dummy_input = torch.randn(self.input_shape).to(self.device)\n","        export_qonnx(self.model, dummy_input, self.export_path)\n","        print(f\"QONNX model exported to: {self.export_path}\\n\")\n","\n","\n","# Salva il modello modificato\n","torch.save(model.state_dict(), os.path.join(SAVE_DIR, f\"{MODEL_NAME}.pth\"))\n","\n","# Esporta in QONNX\n","qonnx_export_path = os.path.join(SAVE_DIR, f\"{MODEL_NAME}.qonnx\")\n","exporter = QONNXExporter(model, MODEL_NAME, input_shape=(1, 1, InputShape, InputShape), export_path=qonnx_export_path)\n","exporter.export()\n","gc.collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzjcOks6u5Lv","executionInfo":{"status":"ok","timestamp":1747671994143,"user_tz":-120,"elapsed":919,"user":{"displayName":"Nicolò Vaccarino","userId":"06934030279554695860"}},"outputId":"4948c5d8-27f5-43c6-df50-af867582e928"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["QONNX model exported to: drive/MyDrive/HPPS_Nico/HPPS/Project/ModelRegression/Weights/Size64/standardRegressionModel_Size64_brevitas_doubleNeuronsAddedPostTrain_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth4_InOutQuant_X3/standardRegressionModel_Size64_brevitas_doubleNeuronsAddedPostTrain_datasetTensorflow01_nameMappingInOrder_1100Class_80train5val15test_lr1e-4_bitWidth4_InOutQuant_X3.qonnx\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["45725"]},"metadata":{},"execution_count":41}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["G5v6EEiB8NYe","HLn8E57n83U9","_sDvgHvuHRzs","68nU-eIx5E-P","afNHyeES4SVp","1I2NKOqc6R_O","xNxBi_CeLpIg"],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}