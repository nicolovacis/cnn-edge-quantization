{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install brevitas\n","!pip install qonnx\n","!pip install onnxoptimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"essIaSsYEQfg","executionInfo":{"status":"ok","timestamp":1748371612485,"user_tz":-120,"elapsed":6257,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}},"outputId":"072830d9-df71-4de5-9dab-456dd0c1bf8e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: brevitas in /usr/local/lib/python3.11/dist-packages (0.12.0)\n","Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.11/dist-packages (from brevitas) (2.0.1)\n","Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.11/dist-packages (from brevitas) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from brevitas) (24.2)\n","Requirement already satisfied: setuptools<70.0 in /usr/local/lib/python3.11/dist-packages (from brevitas) (69.5.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from brevitas) (1.13.1)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from brevitas) (2.6.0+cu124)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from brevitas) (4.13.2)\n","Requirement already satisfied: unfoldNd in /usr/local/lib/python3.11/dist-packages (from brevitas) (0.2.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->brevitas) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->brevitas) (3.0.2)\n","Requirement already satisfied: qonnx in /usr/local/lib/python3.11/dist-packages (0.4.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from qonnx) (25.3.0)\n","Requirement already satisfied: clize>=5.0.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (5.0.2)\n","Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (from qonnx) (3.20.3)\n","Requirement already satisfied: bitstring>=3.1.7 in /usr/local/lib/python3.11/dist-packages (from qonnx) (4.3.1)\n","Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.26.4)\n","Requirement already satisfied: onnx>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.17.0)\n","Requirement already satisfied: onnxruntime>=1.16.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.22.0)\n","Requirement already satisfied: sigtools>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from qonnx) (4.0.1)\n","Requirement already satisfied: toposort>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from qonnx) (1.10)\n","Requirement already satisfied: bitarray<4.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bitstring>=3.1.7->qonnx) (3.4.2)\n","Requirement already satisfied: od in /usr/local/lib/python3.11/dist-packages (from clize>=5.0.1->qonnx) (2.0.2)\n","Requirement already satisfied: docutils>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from clize>=5.0.1->qonnx) (0.21.2)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->qonnx) (1.13.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.16.1->qonnx) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.16.1->qonnx) (1.3.0)\n","Requirement already satisfied: onnxoptimizer in /usr/local/lib/python3.11/dist-packages (0.3.13)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxoptimizer) (1.17.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxoptimizer) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxoptimizer) (3.20.3)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2ypFW2uErVx","executionInfo":{"status":"ok","timestamp":1748371625078,"user_tz":-120,"elapsed":12583,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}},"outputId":"c08f41fb-f658-449a-9e85-941d187db03e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import random\n","import cv2\n","import torch\n","import tensorflow as tf\n","from torch.utils.data import DataLoader, TensorDataset\n","import pandas as pd\n","\n","# STO IGNORANDO LA CLASSE INTERMEDIA\n","class Preprocessing:\n","    def __init__(self, seed=1234, input_size=(560, 560)):\n","        self.seed = seed\n","        self.input_size = input_size\n","\n","        random.seed(self.seed)\n","        os.environ['PYTHONHASHSEED'] = str(self.seed)\n","        np.random.seed(self.seed)\n","        tf.random.set_seed(self.seed)\n","        tf.compat.v1.set_random_seed(self.seed)\n","\n","    def resize_images(self, images):\n","        resized_images = []\n","        for img in images:\n","            img = img.squeeze()\n","            img = cv2.resize(img.astype(np.float32), self.input_size, interpolation=cv2.INTER_AREA)\n","            img = np.expand_dims(img, axis=-1)\n","            resized_images.append(img)\n","        return np.array(resized_images, dtype=np.float32)\n","\n","    #NPZ structure - Y: 6 tot columns, only last 3 to use (one hot encoded)\n","    def load_dataset(self, file_path):\n","        print(f\"Loading dataset from: {file_path}\\n\")\n","        data = np.load(file_path)\n","        X_train = data[\"X_train\"]\n","        Y_train = data[\"Y_train\"]\n","        X_val = data[\"X_val\"]\n","        Y_val = data[\"Y_val\"]\n","        X_test = data[\"X_test\"]\n","        Y_test = data[\"Y_test\"]\n","\n","        def remove_class_1(X, Y):\n","            class_indices = np.argmax(Y[:, 3:], axis=1)\n","            mask = class_indices != 1\n","            return X[mask], Y[mask]\n","\n","        X_train, Y_train = remove_class_1(X_train, Y_train)\n","        X_val, Y_val = remove_class_1(X_val, Y_val)\n","        X_test, Y_test = remove_class_1(X_test, Y_test)\n","\n","        X_train = self.resize_images(X_train)\n","        X_val = self.resize_images(X_val)\n","        X_test = self.resize_images(X_test)\n","\n","        return X_train, Y_train, X_val, Y_val, X_test, Y_test\n","\n","    #It returns one hot encoding Y in Y_test shape (6 columns --> only used 4th and 6th) to match the same shape for test_dataloader\n","    def load_strange_dataset(self, image_dir, label_csv):\n","        class_labels_df = pd.read_csv(label_csv)\n","\n","        # Map only 0 and 100 to the correct one-hot columns (class 1 at index 3, class 2 at index 5)\n","        valid_classes = {0: 3, 100: 5}\n","        selected_indices = class_labels_df[\"Classe\"].isin(valid_classes.keys())\n","        filtered_df = class_labels_df[selected_indices]\n","\n","        Y_strange = np.zeros((len(filtered_df), 6), dtype=np.float32)\n","        for i, val in enumerate(filtered_df[\"Classe\"]):\n","            Y_strange[i, valid_classes[val]] = 1.0\n","\n","        valid_image_formats = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n","        image_filenames = sorted([\n","            img for img in os.listdir(image_dir)\n","            if img.lower().endswith(valid_image_formats)\n","        ])\n","\n","        # Filter image filenames based on the selected rows\n","        filtered_image_filenames = [image_filenames[i] for i in range(len(image_filenames)) if selected_indices.iloc[i]]\n","\n","        X_strange = []\n","        for image_name in filtered_image_filenames:\n","            image_path = os.path.join(image_dir, image_name)\n","            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","            if image is not None:\n","                image = cv2.resize(image, self.input_size)\n","                image = image.astype('float32') / 255.0\n","                X_strange.append(image)\n","\n","        X_strange = np.array(X_strange)\n","        X_strange = np.expand_dims(X_strange, axis=-1)  # NHWC format to match the others\n","\n","        print(f\"Strange dataset loaded: {X_strange.shape}, Labels: {Y_strange.shape}\")\n","        return X_strange, Y_strange\n","\n","\n","\n","    def train_val_dataloaders(self, X_train, Y_train, X_val, Y_val, batch_size=16):\n","        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\n","        X_val_tensor = torch.tensor(X_val, dtype=torch.float32).permute(0, 3, 1, 2)\n","\n","        Y_train_binary = Y_train[:, [3, 5]]\n","        Y_val_binary = Y_val[:, [3, 5]]\n","        Y_train_tensor = torch.tensor(np.argmax(Y_train_binary, axis=-1), dtype=torch.long)\n","        Y_val_tensor = torch.tensor(np.argmax(Y_val_binary, axis=-1), dtype=torch.long)\n","\n","        train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n","        val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n","\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","        return train_loader, val_loader\n","\n","\n","    def test_dataloader(self, X, Y, batch_size=32, one_hot_labels=True):\n","        X_tensor = torch.tensor(X, dtype=torch.float32)\n","        if X_tensor.shape[-1] == 1:\n","            X_tensor = X_tensor.permute(0, 3, 1, 2)\n","\n","        # !!! if one hot encoded -> only use 4th and 6th column for the label !!!\n","        if one_hot_labels:\n","            Y_binary = Y[:, [3, 5]]\n","            Y_tensor = torch.tensor(np.argmax(Y_binary, axis=-1), dtype=torch.long)\n","        else:\n","            Y_tensor = torch.tensor(Y, dtype=torch.long)\n","\n","        dataset = TensorDataset(X_tensor, Y_tensor)\n","        return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n"],"metadata":{"id":"eSvHzshj8qqw","executionInfo":{"status":"ok","timestamp":1748371641918,"user_tz":-120,"elapsed":16834,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import brevitas.nn as qnn\n","import torch.nn.functional as F\n","from brevitas.quant import Int8ActPerTensorFloat\n","\n","#-------------------\n","#   CONFIG MODEL\n","#-------------------\n","x=2\n","InOutQuant=True\n","bit_width = 8\n","#-------------------\n","\n","class StandardModel(torch.nn.Module):\n","    def __init__(self, input_shape, elastic_lambda=1e-4):\n","        super(StandardModel, self).__init__()\n","\n","        self.conv1 = qnn.QuantConv2d(\n","            input_shape[0], 8*x, kernel_size=3, stride=1, padding=1, weight_bit_width=bit_width,\n","            input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","\n","        self.conv2 = qnn.QuantConv2d(\n","            8*x, 12*x, kernel_size=3, stride=1, padding=1, weight_bit_width=bit_width,\n","            input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","\n","        self.conv3 = qnn.QuantConv2d(\n","            12*x, 16*x, kernel_size=3, stride=1, padding=1, weight_bit_width=bit_width,\n","            input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","\n","        self.conv4 = qnn.QuantConv2d(\n","            16*x, 20*x, kernel_size=3, stride=1, padding=1, weight_bit_width=bit_width,\n","            input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","\n","        self.conv5 = qnn.QuantConv2d(\n","            20*x, 24*x, kernel_size=3, stride=1, padding=1, weight_bit_width=bit_width,\n","            input_quant=Int8ActPerTensorFloat, output_quant=Int8ActPerTensorFloat)\n","\n","        self.relu1 = qnn.QuantReLU(bit_width=bit_width)\n","        self.relu2 = qnn.QuantReLU(bit_width=bit_width)\n","        self.relu3 = qnn.QuantReLU(bit_width=bit_width)\n","        self.relu4 = qnn.QuantReLU(bit_width=bit_width)\n","        self.relu5 = qnn.QuantReLU(bit_width=bit_width)\n","        self.relu_fc1 = qnn.QuantReLU(bit_width=bit_width)\n","\n","        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.global_pool = torch.nn.AdaptiveAvgPool2d(1)\n","\n","        self.fc1 = qnn.QuantLinear(24*x, 16*x, weight_bit_width=bit_width)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.fc2 = qnn.QuantLinear(16*x, 2, weight_bit_width=bit_width)\n","\n","        self.l1_lambda = elastic_lambda\n","        self.l2_lambda = elastic_lambda\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu1(self.conv1(x)))\n","        x = self.pool(self.relu2(self.conv2(x)))\n","        x = self.pool(self.relu3(self.conv3(x)))\n","        x = self.pool(self.relu4(self.conv4(x)))\n","        x = self.pool(self.relu5(self.conv5(x)))\n","        x = self.global_pool(x)\n","\n","        x = torch.flatten(x, 1)\n","        x = self.relu_fc1(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"qXrW18QW8giG","executionInfo":{"status":"ok","timestamp":1748371652284,"user_tz":-120,"elapsed":10360,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YHcFQLCs8VYl","executionInfo":{"status":"ok","timestamp":1748371652545,"user_tz":-120,"elapsed":257,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import f1_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","class Trainer:\n","    def __init__(self, model, train_loader, val_loader,\n","                 output_dir, model_name,\n","                 input_shape=(1, 300, 300), num_epochs=300, learning_rate=0.001,\n","                 early_stopping_patience=10, device=None):\n","\n","        self.model = model\n","        self.num_epochs = num_epochs\n","        self.learning_rate = learning_rate\n","        self.early_stopping_patience = early_stopping_patience\n","        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.model.to(self.device)\n","\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n","\n","        self.history = {\n","            'loss': [], 'val_loss': [],\n","            'accuracy': [], 'val_accuracy': [],\n","            'f1_score': [], 'val_f1_score': []\n","        }\n","\n","        self.model_name=model_name\n","        self.save_dir = os.path.join(output_dir, \"model_train_val\")\n","        self.log_file = os.path.join(self.save_dir, \"training_log.txt\")\n","        os.makedirs(self.save_dir, exist_ok=True)\n","\n","    def train(self):\n","        best_val_f1 = -1.0\n","        patience_counter = 0\n","\n","        with open(self.log_file, \"w\") as log:\n","            for epoch in range(self.num_epochs):\n","                train_loss, train_acc, train_f1 = self._run_epoch()\n","                val_loss, val_acc, val_f1 = self._validate()\n","\n","                self.history['loss'].append(train_loss)\n","                self.history['val_loss'].append(val_loss)\n","                self.history['accuracy'].append(train_acc)\n","                self.history['val_accuracy'].append(val_acc)\n","                self.history['f1_score'].append(train_f1)\n","                self.history['val_f1_score'].append(val_f1)\n","\n","                log.write(f\"Epoch {epoch+1}/{self.num_epochs} - \"\n","                          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n","                          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\\n\")\n","\n","                if epoch == 0 or val_f1 > best_val_f1:\n","                    best_val_f1 = val_f1\n","                    patience_counter = 0\n","                else:\n","                    patience_counter += 1\n","                    if patience_counter >= self.early_stopping_patience:\n","                        log.write(\"Early stopping triggered (by val_f1).\\n\")\n","                        break\n","\n","\n","        #self.model.load_state_dict(torch.load(\"best_model.pth\"))\n","        self._save_metrics()\n","        torch.save(self.model.state_dict(), os.path.join(self.save_dir, f\"brevitas_{self.model_name}.pth\"))\n","\n","    def _run_epoch(self):\n","        self.model.train()\n","        total_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_labels = []\n","\n","        for X_batch, Y_batch in self.train_loader:\n","            X_batch, Y_batch = X_batch.to(self.device), Y_batch.to(self.device)\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(X_batch)\n","            loss = self.criterion(outputs, Y_batch)\n","\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            total_loss += loss.item() * X_batch.size(0)\n","            _, predicted = outputs.max(1)\n","            correct += predicted.eq(Y_batch).sum().item()\n","            total += Y_batch.size(0)\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(Y_batch.cpu().numpy())\n","\n","        avg_loss = total_loss / len(self.train_loader.dataset)\n","        accuracy = correct / total\n","        f1 = f1_score(all_labels, all_preds, average='macro')\n","        return avg_loss, accuracy, f1\n","\n","    def _validate(self):\n","        self.model.eval()\n","        total_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_labels = []\n","\n","        with torch.no_grad():\n","            for X_batch, Y_batch in self.val_loader:\n","                X_batch, Y_batch = X_batch.to(self.device), Y_batch.to(self.device)\n","\n","                outputs = self.model(X_batch)\n","                loss = self.criterion(outputs, Y_batch)\n","\n","                total_loss += loss.item() * X_batch.size(0)\n","                _, predicted = outputs.max(1)\n","                correct += predicted.eq(Y_batch).sum().item()\n","                total += Y_batch.size(0)\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_labels.extend(Y_batch.cpu().numpy())\n","\n","        avg_loss = total_loss / len(self.val_loader.dataset)\n","        accuracy = correct / total\n","        f1 = f1_score(all_labels, all_preds, average='macro')\n","        return avg_loss, accuracy, f1\n","\n","    def _save_metrics(self):\n","        for key, values in self.history.items():\n","            path = os.path.join(self.save_dir, f\"{key}.npy\")\n","            np.save(path, np.array(values))\n","\n","        fig = plt.figure(figsize=(10, 5))\n","\n","        plt.subplot(1, 2, 1)\n","        plt.plot(self.history['loss'], label='Train Loss')\n","        plt.plot(self.history['val_loss'], label='Val Loss')\n","        plt.title('Loss')\n","        plt.legend()\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(self.history['accuracy'], label='Train Acc')\n","        plt.plot(self.history['val_accuracy'], label='Val Acc')\n","        plt.plot(self.history['f1_score'], label='Train F1')\n","        plt.plot(self.history['val_f1_score'], label='Val F1')\n","        plt.title('Accuracy & F1-Score')\n","        plt.legend()\n","\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(self.save_dir, \"training_curves.png\"))\n","        plt.close(fig)\n"]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","class Tester:\n","    def __init__(self, model, output_dir, model_name):\n","        self.model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.model.eval()\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","        self.output_dir = os.path.join(output_dir, \"model_test\")\n","        os.makedirs(self.output_dir, exist_ok=True)\n","        self.prefix = model_name.lower()\n","\n","    def evaluate(self, dataloader, prefix_suffix=\"\"):\n","        y_true, y_pred = [], []\n","        with torch.no_grad():\n","            for X_batch, Y_batch in dataloader:\n","                X_batch = X_batch.to(self.device)\n","                outputs = self.model(X_batch)\n","                preds = torch.argmax(outputs, dim=1)\n","                y_pred.extend(preds.cpu().numpy())\n","                y_true.extend(Y_batch.numpy())\n","\n","        y_true, y_pred = np.array(y_true), np.array(y_pred)\n","        acc = np.mean(y_true == y_pred)\n","        cm = confusion_matrix(y_true, y_pred)\n","\n","        prefix = f\"{prefix_suffix}_{self.prefix}\" if prefix_suffix else self.prefix\n","        with open(os.path.join(self.output_dir, f\"{prefix}_accuracy.txt\"), \"w\") as f:\n","            f.write(f\"Accuracy: {acc:.4f}\\n\")\n","\n","        np.save(os.path.join(self.output_dir, f\"{prefix}_predictions.npy\"), y_pred)\n","        np.save(os.path.join(self.output_dir, f\"{prefix}_ground_truth.npy\"), y_true)\n","\n","        disp = ConfusionMatrixDisplay(cm)\n","        disp.plot()\n","        plt.title(f\"Confusion Matrix - {prefix}\")\n","        plt.savefig(os.path.join(self.output_dir, f\"{prefix}_confusion_matrix.png\"))\n","        plt.close()\n","\n","        return acc, cm\n"],"metadata":{"id":"CvrMs9MQ8wD9","executionInfo":{"status":"ok","timestamp":1748371652580,"user_tz":-120,"elapsed":31,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","from brevitas.export import export_qonnx\n","\n","class QONNXExporter:\n","    def __init__(self, model, model_name, input_shape, export_path):\n","        self.model = model\n","        self.model_name = model_name\n","        self.input_shape = input_shape\n","        self.export_path = export_path\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def export(self):\n","        self.model.to(self.device)\n","        self.model.eval()\n","        dummy_input = torch.randn(self.input_shape).to(self.device)\n","\n","        export_qonnx(self.model, dummy_input, self.export_path)\n","        print(f\"QONNX model exported to: {self.export_path}\\n\")\n"],"metadata":{"id":"lB0lN8xk80bn","executionInfo":{"status":"ok","timestamp":1748371652681,"user_tz":-120,"elapsed":95,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# --- CONFIGURATION SECTION ---\n","dataset_path = \"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelClassification/Dataset/preprocessed_binary_dataset.npz\"\n","strange_img_dir = \"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelClassification/Dataset/strange_images/Immagini\"\n","strange_label_csv = \"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelClassification/Dataset/strange_images_classes.csv\"\n","\n","batch_size = 32\n","epochs = 300\n","learning_rate = 0.001\n","input_size = 128\n","\n","export_dir = f\"drive/MyDrive/HPPS_Nico/HPPS/Project/ModelClassification/Weights/Final/Size{input_size}\"\n","if InOutQuant:\n","  model_name = f\"standardModel2Class_binaryDataset_ReluFixed_size{input_size}_InOutQuant_x{x}_weightBitW{bit_width}\"\n","else:\n","  model_name = f\"standardModel2Class_binaryDataset_ReluFixed_size{input_size}_NOInOutQuant_x{x}_weightBitW{bit_width}\"\n","\n","# -----------------------------\n","\n","def main():\n","    input_shape = (1, input_size, input_size)\n","    qonnx_input_shape = (1, 1, input_size, input_size)\n","\n","    save_dir = os.path.join(export_dir, model_name)\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # --- Preprocessing ---\n","    prep = Preprocessing(input_size=(input_size, input_size))\n","\n","    X_train, Y_train, X_val, Y_val, X_test, Y_test = prep.load_dataset(dataset_path)\n","    X_strange, Y_strange = prep.load_strange_dataset(strange_img_dir, strange_label_csv)\n","    print(f\"X_strange: {X_strange.shape}, Y_strange: {Y_strange.shape}\")\n","    print(f\"X_test: {X_test.shape}, Y_test: {Y_test.shape}\")\n","\n","    train_loader, val_loader = prep.train_val_dataloaders(X_train, Y_train, X_val, Y_val, batch_size=batch_size)\n","    test_loader = prep.test_dataloader(X_test, Y_test, batch_size=batch_size, one_hot_labels=True)\n","    strange_loader = prep.test_dataloader(X_strange, Y_strange, batch_size=batch_size, one_hot_labels=True)\n","\n","    # --- Model ---\n","    model = StandardModel(input_shape=input_shape)\n","\n","    # --- Training ---\n","    trainer = Trainer(model, train_loader, val_loader,\n","                      output_dir=save_dir,\n","                      model_name=model_name,\n","                      input_shape=input_shape,\n","                      num_epochs=epochs,\n","                      learning_rate=learning_rate)\n","\n","    trainer.train()\n","\n","    # --- Testing ---\n","    tester = Tester(model=model, output_dir=save_dir, model_name=model_name)\n","    tester.evaluate(test_loader, prefix_suffix=\"test\")\n","    tester.evaluate(strange_loader, prefix_suffix=\"strange\")\n","\n","    # --- Export QONNX ---\n","    onnx_model_path = os.path.join(save_dir, f\"qonnx_{model_name}.onnx\")\n","    exporter = QONNXExporter(model, model_name=model_name, input_shape=qonnx_input_shape, export_path=onnx_model_path)\n","    exporter.export()\n","\n","    # --- FINN Build ---\n","    #builder = Builder(onnx_model_path, save_dir, input_shape=qonnx_input_shape, model_name=model_name)\n","    #builder.build()\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"2REWkgOD84FI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748372058047,"user_tz":-120,"elapsed":405371,"user":{"displayName":"Nicolò Vacis","userId":"05722232897843147151"}},"outputId":"926d8bf4-58f5-47bd-dc35-2ecb6d4f585e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading dataset from: drive/MyDrive/HPPS_Nico/HPPS/Project/ModelClassification/Dataset/preprocessed_binary_dataset.npz\n","\n","Strange dataset loaded: (34, 128, 128, 1), Labels: (34, 6)\n","X_strange: (34, 128, 128, 1), Y_strange: (34, 6)\n","X_test: (862, 128, 128, 1), Y_test: (862, 6)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1624: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1935.)\n","  return super().rename(names)\n"]},{"output_type":"stream","name":"stdout","text":["QONNX model exported to: drive/MyDrive/HPPS_Nico/HPPS/Project/ModelClassification/Weights/Final/Size128/standardModel2Class_binaryDataset_ReluFixed_size128_InOutQuant_x2_weightBitW8/qonnx_standardModel2Class_binaryDataset_ReluFixed_size128_InOutQuant_x2_weightBitW8.onnx\n","\n"]}]}]}